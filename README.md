# ğŸ™ï¸ VoiceAgent

A **production-grade voice agent platform** with multiple interfaces - CLI and Web. Built with OpenAI Agents SDK, Groq's AI models, and Orpheus TTS. Create AI-powered voice assistants that can hear, think, and speak naturally.

## âœ¨ Features

-   ğŸ¤ **Speech-to-Text**: Powered by Groq's Whisper models for fast, accurate transcription
-   ğŸ¤– **Intelligent Agent**: Uses Groq's Llama models via OpenAI Agents SDK for natural conversations
-   ğŸ”Š **Text-to-Speech**: Orpheus TTS via LM Studio for high-quality voice synthesis
-   ğŸ­ **Multiple Voices**: 8 different voices (tara, leah, jess, leo, dan, mia, zac, zoe)
-   ğŸ”„ **Complete Pipeline**: Seamless audio â†’ text â†’ AI â†’ speech â†’ audio workflow
-   ğŸ“¦ **Multiple Interfaces**: CLI menu-driven interface and modern Web UI with WebSocket support
-   âš™ï¸ **Configurable**: Environment-based configuration with sensible defaults
-   ğŸš€ **Production-Ready**: Clean code, error handling, and logging

## ğŸ—ï¸ Architecture

### High-Level Overview

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        User Interfaces                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚      CLI Interface          â”‚      Web Application              â”‚
â”‚   (Python Menu-Driven)      â”‚   (React + TypeScript + Vite)     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â”‚                              â”‚
               â”‚                              â”‚ WebSocket (WS)
               â”‚                              â”‚ REST API (/api)
               â–¼                              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      Backend Services                            â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚            FastAPI Backend (Python)                      â”‚   â”‚
â”‚  â”‚  - REST API endpoints (/api/health, /api/settings)      â”‚   â”‚
â”‚  â”‚  - WebSocket server (/ws) for real-time communication    â”‚   â”‚
â”‚  â”‚  - VoiceService wrapper for VoiceAgent integration       â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â”‚
                           â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Core Voice Agent Library                      â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚            OpenAI Agents SDK                             â”‚   â”‚
â”‚  â”‚  - VoicePipeline for audio processing                    â”‚   â”‚
â”‚  â”‚  - SingleAgentVoiceWorkflow                              â”‚   â”‚
â”‚  â”‚  - CustomVoiceModelProvider                              â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â”‚                              â”‚
       â”Œâ”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
       â”‚   STT (Groq)  â”‚            â”‚   LLM (Groq)      â”‚
       â”‚  Whisper-v3   â”‚            â”‚  Llama-3.3-70b    â”‚
       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â”‚                              â”‚
               â”‚                              â”‚
       â”Œâ”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
       â”‚            TTS (Orpheus via LM Studio)         â”‚
       â”‚  - SNAC decoder for audio generation           â”‚
       â”‚  - Local LM Studio server (port 1234)          â”‚
       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Pipeline Flow

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Audio Input â”‚  (Microphone / Web Browser)
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  STT (Groq) â”‚  â—„â”€â”€ whisper-large-v3
â”‚  Transcribe â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
       â”‚ (text)
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚    Agent    â”‚  â—„â”€â”€ llama-3.3-70b-versatile
â”‚  (OpenAI)   â”‚      OpenAI Agents SDK
â”‚  Process    â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
       â”‚ (text response)
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚TTS (Orpheus)â”‚  â—„â”€â”€ lex-au/Orpheus-3b-FT-Q4_K_M.gguf
â”‚ (LM Studio) â”‚      SNAC Decoder
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
       â”‚ (audio)
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚Audio Output â”‚  (Speakers / Web Browser)
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ› ï¸ Tech Stack

### Backend

-   **Python 3.10+** - Core language
-   **FastAPI** - Modern, fast web framework for building APIs
-   **Uvicorn** - ASGI server for FastAPI
-   **WebSockets** - Real-time bidirectional communication
-   **Pydantic** - Data validation using Python type annotations
-   **Rich** - Terminal formatting library

### Frontend

-   **React 18** - UI library
-   **TypeScript** - Type-safe JavaScript
-   **Vite** - Fast build tool and dev server
-   **TailwindCSS** - Utility-first CSS framework
-   **WebSocket API** - Browser WebSocket client

### AI & Voice Processing

-   **OpenAI Agents SDK** - Agent framework and voice pipeline
-   **Groq** - Fast inference for STT (Whisper) and LLM (Llama)
-   **LM Studio** - Local model runtime for TTS
-   **Orpheus TTS** - High-quality open-source text-to-speech model
-   **SNAC Decoder** - Audio generation decoder for Orpheus

### Audio Processing

-   **sounddevice** - Audio I/O library (Python)
-   **soundfile** - Audio file I/O library
-   **numpy** - Numerical computing
-   **scipy** - Scientific computing (signal processing)

### Build & Package Management

-   **UV** - Fast Python package installer and resolver
-   **npm** - JavaScript package manager
-   **Hatchling** - Python build backend

## ğŸ“‹ Prerequisites

-   **Python 3.10 or higher**
-   **Node.js 18+ and npm** (for web interface)
-   **UV package manager** (recommended) or pip
-   **Groq API key** ([Get one here](https://console.groq.com))
-   **LM Studio** with Orpheus TTS model installed
-   **Microphone and speakers/headphones**
-   **ffmpeg** (optional, for WebM conversion in web interface)

### Setting up LM Studio

1. Download and install [LM Studio](https://lmstudio.ai/)
2. In LM Studio, search for and download: `lex-au/Orpheus-3b-FT-Q4_K_M.gguf`
3. Load the model in LM Studio
4. **IMPORTANT**: Start the local server (default: http://localhost:1234/v1)
    - The server must be running for TTS to work
    - Orpheus TTS uses the `/completions` endpoint (not `/chat/completions`)

Reference: [Orpheus TTS Local](https://github.com/isaiahbjork/orpheus-tts-local)

## ğŸš€ Quick Start

### 1. Install UV Package Manager

```bash
# macOS/Linux
curl -LsSf https://astral.sh/uv/install.sh | sh

# Or with pip
pip install uv
```

### 2. Clone and Setup

```bash
# Clone the repository
cd VoiceAgent

# Create virtual environment with UV
uv venv

# Activate virtual environment
source .venv/bin/activate  # On Windows: .venv\Scripts\activate

# Install dependencies
uv pip install -e .
```

### 3. Configure Environment

Create a `.env` file in the project root:

```bash
# Copy example (if exists)
cp .env.example .env

# Edit with your API key
nano .env
```

Add your configuration:

```env
GROQ_API_KEY=your_groq_api_key_here
LM_STUDIO_URL=http://localhost:1234/v1
TTS_VOICE=tara
```

### 4. Run CLI Interface

```bash
python main.py
```

This launches the **interactive menu** where you can:

-   ğŸ¤ Start voice conversations
-   ğŸ’¬ Chat with text + voice responses
-   ğŸ“ Text-only chat mode
-   âš™ï¸ Configure agent settings
-   ğŸ¯ Quick test functionality
-   â„¹ï¸ View system information

### 5. Run Web Application

```bash
# Start both backend and frontend
./start_web.sh

# Or manually:
# Terminal 1 - Backend
cd backend
python -m uvicorn main:app --host 0.0.0.0 --port 8000 --reload

# Terminal 2 - Frontend
cd frontend
npm install  # First time only
npm run dev
```

Access the web interface at: **http://localhost:5173**

Backend API available at: **http://localhost:8000**

## ğŸ‘¤ User Journey

### CLI Interface Journey

1. **Launch Application**: Run `python main.py` from terminal
2. **Main Menu**: Choose from 7 options:
    - Voice conversation (full audio interaction)
    - Text chat with voice response
    - Text-only chat
    - Configure settings
    - Quick test
    - System info
    - Exit
3. **Voice Conversation**:
    - System records audio (5 seconds default)
    - Audio sent to Groq STT for transcription
    - Text processed by Llama LLM via OpenAI Agents SDK
    - Response synthesized by Orpheus TTS via LM Studio
    - Audio played through speakers
    - Conversation continues until user exits
4. **Text Chat**: Type messages, receive voice responses
5. **Settings**: Configure voice, temperature, max tokens, etc.

### Web Interface Journey

1. **Access Web App**: Open browser to `http://localhost:5173`
2. **Initial Connection**: WebSocket automatically connects to backend
3. **Voice Interaction**:
    - Click the animated circle to start recording
    - Speak into microphone (browser captures audio)
    - Click circle again or "Stop & Send" button
    - Audio chunks sent via WebSocket to backend
    - Backend processes through Voice Agent pipeline
    - Transcription displayed in conversation history
    - Audio response streamed back and played
    - System returns to idle state
4. **Text Interaction**: Type message in input field, press Send
5. **Settings**: Click Settings tab to configure agent behavior
6. **Real-time Updates**: State changes reflected via WebSocket (listening, processing, speaking)

### Audio Flow (Web)

```
Browser Microphone
    â†“
Web Audio API (MediaRecorder)
    â†“
Base64 Encoded Chunks
    â†“
WebSocket â†’ Backend
    â†“
VoiceService.process_audio_chunk()
    â†“
VoiceAgent.process_voice_input()
    â†“
Pipeline: STT â†’ Agent â†’ TTS
    â†“
Audio Response Streamed
    â†“
WebSocket â†’ Browser
    â†“
AudioContext.playPCM()
    â†“
Speakers
```

### Audio Format Details

The web interface uses **raw PCM audio format** for consistent playback:

-   **Input Processing**: `process_audio_chunk()` accepts audio chunks (WebM or WAV) from the browser, converts them to numpy arrays, and processes through the voice agent pipeline
-   **Output Format**: Both `process_audio_chunk()` and `process_text_message()` return **raw PCM data** (16-bit, mono, 24kHz) in **4KB chunks** for streaming
-   **Format Consistency**: Standardized audio format ensures reliable playback across different browsers and audio contexts
-   **Streaming**: Audio is streamed in chunks via WebSocket for low-latency, real-time playback

## ğŸ“ Project Structure

```
VoiceAgent/
â”œâ”€â”€ src/voiceagent/              # Core Voice Agent library
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ core/
â”‚   â”‚   â””â”€â”€ voice_agent.py       # Main VoiceAgent class
â”‚   â”œâ”€â”€ models/                  # Model providers
â”‚   â”‚   â”œâ”€â”€ groq_stt.py          # Groq Whisper STT
â”‚   â”‚   â”œâ”€â”€ orpheus_tts.py       # Orpheus TTS via LM Studio
â”‚   â”‚   â”œâ”€â”€ groq_llm.py          # Groq LLM via LiteLLM
â”‚   â”‚   â””â”€â”€ voice_provider.py    # Custom VoiceModelProvider
â”‚   â”œâ”€â”€ config/
â”‚   â”‚   â””â”€â”€ settings.py          # Configuration settings
â”‚   â””â”€â”€ audio/                   # Audio utilities
â”‚
â”œâ”€â”€ backend/                     # FastAPI web backend
â”‚   â”œâ”€â”€ main.py                  # FastAPI application
â”‚   â”œâ”€â”€ config.py                # Backend configuration
â”‚   â”œâ”€â”€ routes/
â”‚   â”‚   â”œâ”€â”€ api.py               # REST API endpoints
â”‚   â”‚   â””â”€â”€ websocket.py         # WebSocket handler
â”‚   â””â”€â”€ services/
â”‚       â””â”€â”€ voice_service.py     # Voice service wrapper
â”‚
â”œâ”€â”€ frontend/                    # React frontend
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ App.tsx              # Main app component
â”‚   â”‚   â”œâ”€â”€ components/
â”‚   â”‚   â”‚   â”œâ”€â”€ VoiceBot.tsx     # Voice interaction component
â”‚   â”‚   â”‚   â”œâ”€â”€ Settings.tsx     # Settings component
â”‚   â”‚   â”‚   â””â”€â”€ AnimatedCircle.tsx
â”‚   â”‚   â”œâ”€â”€ hooks/
â”‚   â”‚   â”‚   â”œâ”€â”€ useWebSocket.ts  # WebSocket hook
â”‚   â”‚   â”‚   â””â”€â”€ useAudio.ts      # Audio recording/playback hook
â”‚   â”‚   â””â”€â”€ utils/
â”‚   â”‚       â”œâ”€â”€ audioRecorder.ts
â”‚   â”‚       â””â”€â”€ audioPlayer.ts
â”‚   â””â”€â”€ package.json
â”‚
â”œâ”€â”€ main.py                      # CLI interface entry point
â”œâ”€â”€ examples/                    # Usage examples
â”œâ”€â”€ pyproject.toml               # UV package config
â”œâ”€â”€ requirements.txt             # Pip compatibility
â”œâ”€â”€ Makefile                     # Build commands
â””â”€â”€ start_web.sh                 # Web app startup script
```

## âš™ï¸ Configuration

All settings can be configured via environment variables in `.env`:

### API Configuration

```env
GROQ_API_KEY=your_key                    # Required: Groq API key
LM_STUDIO_URL=http://localhost:1234/v1   # LM Studio server URL
TTS_VOICE=tara                           # Orpheus TTS voice
```

### Model Configuration

```env
STT_MODEL=whisper-large-v3               # Speech-to-text model (Groq)
LLM_MODEL=llama-3.3-70b-versatile        # LLM for agent (Groq)
```

### Agent Configuration

```env
AGENT_NAME=VoiceAssistant
AGENT_INSTRUCTIONS="You are a helpful voice assistant..."
MAX_TOKENS=500                           # Max response length
TEMPERATURE=0.7                          # Creativity (0.0-1.0)
```

### Audio Configuration

```env
SAMPLE_RATE=24000        # Audio sample rate (Hz)
CHANNELS=1               # Audio channels
CHUNK_SIZE=1024          # Recording chunk size
```

## ğŸ¨ Available Voices

Orpheus TTS supports 8 different voices:

-   **tara** (default) - Best overall voice for general use
-   **leah** - Clear female voice
-   **jess** - Friendly female voice
-   **leo** - Professional male voice
-   **dan** - Casual male voice
-   **mia** - Expressive female voice
-   **zac** - Energetic male voice
-   **zoe** - Calm female voice

Change voice in `.env` or via Settings UI in web interface.

## ğŸ“– Usage Examples

### CLI Interface

```bash
# Interactive menu (default)
python main.py

# Direct voice conversation
python main.py --mode voice --turns 5

# Text mode
python main.py --mode text --message "Hello, how are you?"

# Custom instructions
python main.py --instructions "You are a pirate captain!"
```

### Programmatic Usage

```python
import asyncio
from voiceagent import VoiceAgent

async def main():
    agent = VoiceAgent()
    await agent.run_conversation(max_turns=3)

asyncio.run(main())
```

## ğŸ› Troubleshooting

### No audio input detected

-   Check microphone permissions
-   Verify microphone is connected and working
-   Adjust `SILENCE_THRESHOLD` in `.env`

### LM Studio connection errors

-   Ensure LM Studio is running
-   Verify local server is started (http://localhost:1234/v1)
-   Check that Orpheus model is loaded
-   Try accessing http://localhost:1234/v1/models in browser

### API errors

-   Verify Groq API key is correct in `.env`
-   Check API rate limits and quotas
-   Ensure internet connection is stable

### Web interface issues

-   Check browser console for errors
-   Verify WebSocket connection (should see "Connected" status)
-   Ensure backend is running on port 8000
-   Check CORS settings in backend/config.py

### Installation issues

```bash
# Reinstall dependencies
uv pip install --force-reinstall -e .

# Clear UV cache
uv cache clean

# Frontend dependencies
cd frontend
rm -rf node_modules package-lock.json
npm install
```

## ğŸš€ Production Deployment

### Best Practices

1. **Security**: Store API keys securely (AWS Secrets Manager, HashiCorp Vault)
2. **Error Handling**: Implement retry logic with exponential backoff
3. **Monitoring**: Log conversations, errors, and performance metrics
4. **Rate Limiting**: Implement request throttling to avoid API limits
5. **Caching**: Cache TTS responses for common phrases
6. **Async**: All operations are async for better performance

### Scaling

-   Use message queues (RabbitMQ, Redis) for high traffic
-   Deploy behind load balancer (NGINX, HAProxy)
-   Consider streaming STT/TTS for lower latency
-   Implement session management for multiple users
-   Use Redis for distributed caching

## ğŸ¤ Contributing

This is a production-ready template. Feel free to extend it:

-   Add more agent tools and functions
-   Integrate with databases for persistence
-   Add multi-language support
-   Improve voice activity detection
-   Create custom TTS voices
-   Add authentication and user management

## ğŸ“ License

MIT License - feel free to use in your projects!

## ğŸ™ Acknowledgments

-   **OpenAI Agents SDK** - Powerful agent framework
-   **Groq** - Fast Whisper STT and Llama LLM models
-   **LM Studio** - Local model runtime
-   **Orpheus TTS** - High-quality open-source TTS ([GitHub](https://github.com/isaiahbjork/orpheus-tts-local))
-   **Rich** - Beautiful terminal output

---

**Built with â¤ï¸ using OpenAI Agents SDK, Groq, and Orpheus TTS**
